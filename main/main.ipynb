{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaee32e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess\n",
    "import Model\n",
    "from tensorflow.keras.callbacks import TensorBoard,ModelCheckpoint\n",
    "import numpy as np\n",
    "from keras.optimizers import adam_v2\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9 # 占用GPU90%的显存\n",
    "sess=tf.compat.v1.Session(config=config)\n",
    "\n",
    "batch_size =64\n",
    "epochs = 20\n",
    "num_classes = 3\n",
    "length = 5120\n",
    "BatchNorm = True # 是否批量归一化\n",
    "number = 200# 每类样本的数量\n",
    "normal = True # 是否标准化\n",
    "rate = [0.7,0.2,0.1] # 测试集验证集划分比例\n",
    "\n",
    "def data_pre(path,number):\n",
    "    x_train, y_train, x_valid, y_valid, x_test, y_test = preprocess.prepro(d_path=path, length=length,\n",
    "                                                                           number=number,\n",
    "                                                                           normal=normal,\n",
    "                                                                           rate=rate,\n",
    "                                                                           enc=False, enc_step=28)\n",
    "    x_train = x_train.astype('float32')\n",
    "    y_train = y_train.astype('float32')\n",
    "    x_valid = x_valid.astype('float32')\n",
    "    y_valid = y_valid.astype('float32')\n",
    "    x_test = x_test.astype('float32')\n",
    "    y_test = y_test.astype('float32')\n",
    "    x_train, x_valid, x_test = x_train[:, :, np.newaxis], x_valid[:, :,np.newaxis], x_test[:, :, np.newaxis]\n",
    "    #x_train, x_valid, x_test = x_train[:, :, np.newaxis, np.newaxis], x_valid[:, :, np.newaxis, np.newaxis], x_test[:, :, np.newaxis, np.newaxis]\n",
    "    return x_train,x_valid,x_test,y_train,y_valid,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eed90ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练样本维度: (8400, 5120, 1)\n",
      "8400 训练样本个数\n",
      "验证样本的维度 (2400, 5120, 1)\n",
      "2400 验证样本个数\n",
      "测试样本的维度 (1200, 5120, 1)\n",
      "1200 测试样本个数\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 5120, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "patch_encoder_cum_1 (PatchEncod (None, 19, 64)       34048       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 19, 64)       12352       patch_encoder_cum_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 19, 64)       12352       patch_encoder_cum_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 19, 64)       12352       patch_encoder_cum_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_4 (Sli (None, 19, 64, 1)    0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_5 (Sli (None, 19, 64, 1)    0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_6 (Sli (None, 19, 64, 1)    0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 19, 64, 3)    0           tf.__operators__.getitem_4[0][0] \n",
      "                                                                 tf.__operators__.getitem_5[0][0] \n",
      "                                                                 tf.__operators__.getitem_6[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean_1 (TFOpLamb (None, 19, 64)       0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concat_class_token_add_pos_embe (None, 20, 64)       1344        tf.math.reduce_mean_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_12 (LayerNo (None, 20, 64)       128         concat_class_token_add_pos_embed_\n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_6 (MultiHe (None, 20, 64)       132672      layer_normalization_12[0][0]     \n",
      "                                                                 layer_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 20, 64)       0           multi_head_attention_6[0][0]     \n",
      "                                                                 concat_class_token_add_pos_embed_\n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_13 (LayerNo (None, 20, 64)       128         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 20, 64)       0           layer_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum_1 (TFOpLambd (None, 20)           0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_7 (Sli (20,)                0           tf.math.reduce_sum_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.top_k_1 (TFOpLambda)    TopKV2(values=(10,), 0           tf.__operators__.getitem_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.gather_1 (TFOpLamb (None, 10, 64)       0           concat_class_token_add_pos_embed_\n",
      "                                                                 tf.math.top_k_1[0][1]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_14 (LayerNo (None, 10, 64)       128         tf.compat.v1.gather_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_7 (MultiHe (None, 10, 64)       132672      layer_normalization_14[0][0]     \n",
      "                                                                 layer_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 10, 64)       0           multi_head_attention_7[0][0]     \n",
      "                                                                 tf.compat.v1.gather_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_15 (LayerNo (None, 10, 64)       128         add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 10, 128)      8320        layer_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 10, 128)      0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 10, 64)       8256        dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 10, 64)       0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 10, 64)       0           dropout_12[0][0]                 \n",
      "                                                                 add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_16 (LayerNo (None, 10, 64)       128         add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_8 (MultiHe (None, 10, 64)       132672      layer_normalization_16[0][0]     \n",
      "                                                                 layer_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 10, 64)       0           multi_head_attention_8[0][0]     \n",
      "                                                                 add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_17 (LayerNo (None, 10, 64)       128         add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 10, 128)      8320        layer_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 10, 128)      0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 10, 64)       8256        dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 10, 64)       0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 10, 64)       0           dropout_14[0][0]                 \n",
      "                                                                 add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_18 (LayerNo (None, 10, 64)       128         add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_9 (MultiHe (None, 10, 64)       132672      layer_normalization_18[0][0]     \n",
      "                                                                 layer_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 10, 64)       0           multi_head_attention_9[0][0]     \n",
      "                                                                 add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_19 (LayerNo (None, 10, 64)       128         add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 10, 128)      8320        layer_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 10, 128)      0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 10, 64)       8256        dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 10, 64)       0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 10, 64)       0           dropout_16[0][0]                 \n",
      "                                                                 add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_20 (LayerNo (None, 10, 64)       128         add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_10 (MultiH (None, 10, 64)       132672      layer_normalization_20[0][0]     \n",
      "                                                                 layer_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 10, 64)       0           multi_head_attention_10[0][0]    \n",
      "                                                                 add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_21 (LayerNo (None, 10, 64)       128         add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 10, 128)      8320        layer_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 10, 128)      0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 10, 64)       8256        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 10, 64)       0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 10, 64)       0           dropout_18[0][0]                 \n",
      "                                                                 add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_22 (LayerNo (None, 10, 64)       128         add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_11 (MultiH (None, 10, 64)       132672      layer_normalization_22[0][0]     \n",
      "                                                                 layer_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 10, 64)       0           multi_head_attention_11[0][0]    \n",
      "                                                                 add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_23 (LayerNo (None, 10, 64)       128         add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 10, 128)      8320        layer_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 10, 128)      0           dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 10, 64)       8256        dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 10, 64)       0           dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 10, 64)       0           dropout_20[0][0]                 \n",
      "                                                                 add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 10, 64)       0           add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 64)           0           dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 3)            195         global_average_pooling1d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 953,091\n",
      "Trainable params: 953,091\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_12/gamma:0', 'layer_normalization_12/beta:0', 'multi_head_attention_6/query/kernel:0', 'multi_head_attention_6/query/bias:0', 'multi_head_attention_6/key/kernel:0', 'multi_head_attention_6/key/bias:0', 'multi_head_attention_6/value/kernel:0', 'multi_head_attention_6/value/bias:0', 'multi_head_attention_6/attention_output/kernel:0', 'multi_head_attention_6/attention_output/bias:0', 'layer_normalization_13/gamma:0', 'layer_normalization_13/beta:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['layer_normalization_12/gamma:0', 'layer_normalization_12/beta:0', 'multi_head_attention_6/query/kernel:0', 'multi_head_attention_6/query/bias:0', 'multi_head_attention_6/key/kernel:0', 'multi_head_attention_6/key/bias:0', 'multi_head_attention_6/value/kernel:0', 'multi_head_attention_6/value/bias:0', 'multi_head_attention_6/attention_output/kernel:0', 'multi_head_attention_6/attention_output/bias:0', 'layer_normalization_13/gamma:0', 'layer_normalization_13/beta:0'] when minimizing the loss.\n",
      "132/132 [==============================] - 8s 36ms/step - loss: 0.4151 - acc: 0.8245 - val_loss: 0.1517 - val_acc: 0.9171\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.91708, saving model to CFSPT.hdf5\n",
      "Epoch 2/20\n",
      "  1/132 [..............................] - ETA: 4s - loss: 0.1148 - acc: 0.9531"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Coder\\Python3.7\\lib\\site-packages\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132/132 [==============================] - 4s 31ms/step - loss: 0.1124 - acc: 0.9456 - val_loss: 0.1983 - val_acc: 0.9075\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.91708\n",
      "Epoch 3/20\n",
      "132/132 [==============================] - 4s 30ms/step - loss: 0.0513 - acc: 0.9819 - val_loss: 0.0238 - val_acc: 0.9937\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.91708 to 0.99375, saving model to CFSPT.hdf5\n",
      "Epoch 4/20\n",
      "132/132 [==============================] - 4s 30ms/step - loss: 0.0193 - acc: 0.9940 - val_loss: 0.0203 - val_acc: 0.9921\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.99375\n",
      "Epoch 5/20\n",
      "132/132 [==============================] - 4s 30ms/step - loss: 0.0219 - acc: 0.9921 - val_loss: 0.0263 - val_acc: 0.9933\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.99375\n",
      "Epoch 6/20\n",
      "132/132 [==============================] - 4s 31ms/step - loss: 0.0159 - acc: 0.9952 - val_loss: 0.0073 - val_acc: 0.9975\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.99375 to 0.99750, saving model to CFSPT.hdf5\n",
      "Epoch 7/20\n",
      "132/132 [==============================] - 4s 30ms/step - loss: 0.0059 - acc: 0.9983 - val_loss: 0.0046 - val_acc: 0.9979\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.99750 to 0.99792, saving model to CFSPT.hdf5\n",
      "Epoch 8/20\n",
      "132/132 [==============================] - 4s 30ms/step - loss: 0.0033 - acc: 0.9994 - val_loss: 0.0066 - val_acc: 0.9975\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.99792\n",
      "Epoch 9/20\n",
      "132/132 [==============================] - 4s 31ms/step - loss: 0.0025 - acc: 0.9992 - val_loss: 0.0057 - val_acc: 0.9979\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.99792\n",
      "Epoch 10/20\n",
      "132/132 [==============================] - 4s 30ms/step - loss: 0.0051 - acc: 0.9986 - val_loss: 0.0049 - val_acc: 0.9975\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.99792\n",
      "Epoch 11/20\n",
      "132/132 [==============================] - 4s 30ms/step - loss: 0.0149 - acc: 0.9962 - val_loss: 0.0253 - val_acc: 0.9933\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.99792\n",
      "Epoch 12/20\n",
      "132/132 [==============================] - 4s 30ms/step - loss: 0.0117 - acc: 0.9968 - val_loss: 0.0084 - val_acc: 0.9975\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.99792\n",
      "Epoch 13/20\n",
      "132/132 [==============================] - 4s 30ms/step - loss: 0.0079 - acc: 0.9974 - val_loss: 0.0040 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.99792 to 0.99917, saving model to CFSPT.hdf5\n",
      "Epoch 14/20\n",
      "132/132 [==============================] - 4s 30ms/step - loss: 0.0082 - acc: 0.9977 - val_loss: 0.0027 - val_acc: 0.9996\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.99917 to 0.99958, saving model to CFSPT.hdf5\n",
      "Epoch 15/20\n",
      "132/132 [==============================] - 4s 30ms/step - loss: 0.0028 - acc: 0.9994 - val_loss: 0.0040 - val_acc: 0.9983\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.99958\n",
      "Epoch 16/20\n",
      "132/132 [==============================] - 4s 30ms/step - loss: 0.0045 - acc: 0.9987 - val_loss: 0.0024 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.99958\n",
      "Epoch 17/20\n",
      "132/132 [==============================] - 4s 31ms/step - loss: 0.0012 - acc: 0.9995 - val_loss: 0.0025 - val_acc: 0.9996\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.99958\n",
      "Epoch 18/20\n",
      "132/132 [==============================] - 4s 30ms/step - loss: 4.9259e-04 - acc: 0.9999 - val_loss: 5.1536e-04 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.99958 to 1.00000, saving model to CFSPT.hdf5\n",
      "Epoch 19/20\n",
      "132/132 [==============================] - 4s 30ms/step - loss: 4.7774e-04 - acc: 0.9999 - val_loss: 0.0019 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 1.00000\n",
      "Epoch 20/20\n",
      "132/132 [==============================] - 4s 30ms/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.0056 - val_acc: 0.9992\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 1.00000\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2737 - acc: 0.9543\n",
      "loss: 0.27366551756858826\n",
      "accuracy 0.954285740852356\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    path = r\".\\Train\"\n",
    "    path_test = r\".\\Test\"\n",
    "    x_train,x_valid,x_test,y_train,y_valid,y_test = data_pre(path,200)\n",
    "    x_train1,x_valid1,x_test1,y_train1,y_valid1,y_test1 = data_pre(path_test,200)\n",
    "    # 输入数据的维度\n",
    "    input_shape =x_train.shape[1:]\n",
    "    print('训练样本维度:', x_train.shape)\n",
    "    print(x_train.shape[0], '训练样本个数')\n",
    "    print('验证样本的维度', x_valid.shape)\n",
    "    print(x_valid.shape[0], '验证样本个数')\n",
    "    print('测试样本的维度', x_test.shape)\n",
    "    print(x_test.shape[0], '测试样本个数')\n",
    "\n",
    "    model = Model.CFSPT(input_shape)\n",
    "    #model.summary()\n",
    "    # 定义优化器\n",
    "    #Nadam1 = Nadam(lr=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-08,schedule_decay=0.004)\n",
    "    adam = adam_v2.Adam(learning_rate=0.001)\n",
    "    # 定义优化器，loss function, 训练过程中计算准确率\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['acc'])\n",
    "    # 画出网络结构\n",
    "    # plot_model(model, to_file='model_cnn.png', show_shapes=True, show_layer_names='False', rankdir='TB')\n",
    "    callback_list = [ModelCheckpoint(filepath='CFSPT.hdf5', verbose=1, save_best_only=True,monitor='val_acc',mode='auto')]\n",
    "    # 训练模型\n",
    "    model.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=epochs,\n",
    "              verbose=1, validation_data=(x_valid, y_valid), shuffle=True,\n",
    "              callbacks=callback_list)\n",
    "\n",
    "    model.load_weights('CFSPT.hdf5')\n",
    "    # 评估模型\n",
    "    #model.summary()\n",
    "    loss, acc = model.evaluate(x_train1, y_train1)\n",
    "    print(\"loss:\", loss)\n",
    "    print(\"accuracy\", acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7cd07f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
